{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab 5: Wide and Deep Networks**\n",
    "### Authors: Will Lahners, Edward Powers, and Nino Castellano\n",
    "\n",
    "## **Describing the Data**\n",
    "\n",
    "The dataset we chose pertains to mushrooms, specifically whether or not they are poisonous, and is called *mushrooms.csv*. We obtained this data from [Kaggle](https://www.kaggle.com/datasets/uciml/mushroom-classification). The results of our model could benefit food production companies, farmers, or people who enjoy the outdoors. \n",
    "\n",
    "We chose this dataset becasue every feature column is a categorical variable, which makes this perfect for a wide and deep neural network. This data set contains descriptions of samples corresponding to 23 species of gilled mushrooms found in the Agaricus and Lepiota Family Mushroom. Each species will be identified to be either definitely edible, definitely poisonous, or unknown edibility. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation (4 points total)\n",
    "\n",
    "> [1 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). You have the option of using tf.dataset for processing, but it is not required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['veil-type'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Deleting Useless Variables\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m data\u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mveil-type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m class_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m     13\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(class_mapping)\n",
      "File \u001b[1;32mc:\\Users\\ncast\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ncast\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\ncast\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ncast\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['veil-type'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# (1) Load the data into a pandas DataFrame\n",
    "data = pd.read_csv('./mushrooms.csv')\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Deleting Useless Variables\n",
    "data= data.drop(columns=['veil-type'])\n",
    "\n",
    "class_mapping = {'e': True, 'p': False}\n",
    "data['class'] = data['class'].map(class_mapping)\n",
    "\n",
    "# Optionally, rename the column to something more descriptive\n",
    "data.rename(columns={'class': 'edible'}, inplace=True)\n",
    "\n",
    "# Encode any string data as integers for now (Credits to ChatGPT)\n",
    "le = LabelEncoder()\n",
    "object_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in object_columns:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    \n",
    "pd.set_option('display.max_columns', None)    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   class                      8124 non-null   object\n",
      " 1   cap-shape                  8124 non-null   object\n",
      " 2   cap-surface                8124 non-null   object\n",
      " 3   cap-color                  8124 non-null   object\n",
      " 4   bruises                    8124 non-null   object\n",
      " 5   odor                       8124 non-null   object\n",
      " 6   gill-attachment            8124 non-null   object\n",
      " 7   gill-spacing               8124 non-null   object\n",
      " 8   gill-size                  8124 non-null   object\n",
      " 9   gill-color                 8124 non-null   object\n",
      " 10  stalk-shape                8124 non-null   object\n",
      " 11  stalk-root                 8124 non-null   object\n",
      " 12  stalk-surface-above-ring   8124 non-null   object\n",
      " 13  stalk-surface-below-ring   8124 non-null   object\n",
      " 14  stalk-color-above-ring     8124 non-null   object\n",
      " 15  stalk-color-below-ring     8124 non-null   object\n",
      " 16  veil-type                  8124 non-null   object\n",
      " 17  veil-color                 8124 non-null   object\n",
      " 18  ring-number                8124 non-null   object\n",
      " 19  ring-type                  8124 non-null   object\n",
      " 20  spore-print-color          8124 non-null   object\n",
      " 21  population                 8124 non-null   object\n",
      " 22  habitat                    8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started by one-hot encoding the each of our variables. We also ended up dropping the 'veil-type' becasue that column did not contain any unique values that would benefit our model. Each column is categorical, with each number (being one-hot encoded) pertaining to a differnet feature of that categorical variable. In the table below, the features of our variables can be found:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Number of Classifications | Types of Classifications |\n",
    "|:-------------|:--------------:|--------------:|\n",
    "| edible        |       2    |           true or false  |\n",
    "| cap-shape         |       6       |          bell, conical, flat, sunken, convex, or knobbed    |\n",
    "| cap-surface        |     4       |        grooves, scaley, smooth, or fiberous   |\n",
    "| cap-color        |     10       |        gray, green, brown, buff, cinamon, pink, purple, red, white, or yellow   |\n",
    "| bruises        |     2       |        true or false   |\n",
    "| odor        |     9       |        fishy, foul, musty, pungent, spicy, anise, creosote, almond, or none   |\n",
    "| gill-attachment        |     4       |        descending, free, attached, or notched   |\n",
    "| gill-spacing        |     3       |        close, distant, or crowded   |\n",
    "| gill-size        |     2       |        broad or narrow   |\n",
    "| gill-color        |     12       |        white, black, brown, chocolate, gray, buff, green, yellow, orange, pink, purple or red   |\n",
    "| stalk-shape        |     2       |        enlarging or taperingg   |\n",
    "| stalk-root        |     7       |        club, cup, equal, rhizomorphs, missing, bulbous, or rooted.   |\n",
    "| stalk-surface-above-ring        |     4       |        scaly, silky, smooth, or fiberous   |\n",
    "| stalk-surface-below-ring        |     4       |        scaly, silky, smooth, or fiberous   |\n",
    "| stalk-color-above-ring        |     8       |        gray, cinnamon, orange, pink, red, yellow, buff, or brown   |\n",
    "| stalk-color-below-ring        |     8       |        gray, cinnamon, orange, pink, red, yellow, buff, or brown   |\n",
    "| veil-type        |     2       |       partial or universal   |\n",
    "| veil-color        |     4       |        brown, orange, yellow, or white   |\n",
    "| ring-number        |     3       |        none, one, or two   |\n",
    "| ring-type        |     8       |        cobwebby, evanscent, flaring, large, none, pendant, sheating, or zone   |\n",
    "| spore-print-color        |     9       |        brown, buff, black, green, orange, purple, white, yellow, or chocolate  |\n",
    "| population        |     6       |        clustered, numerous, scattered, several, solitary, or abundant    |\n",
    "| habitat        |     7       |        grasses, meadows, leaves, paths, urban, woods or waste   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [1 points] Identify groups of features in your data that should be combined into cross-product features. Provide a compelling justification for why these features should be crossed (or why some features should not be crossed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import FeatureSpace\n",
    "\n",
    "#Creating Feature Spaces\n",
    "feature_space= FeatureSpace(\n",
    "    features= {\n",
    "        \"cap-shape\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"cap-surface\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"cap-color\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"bruises\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"odor\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"gill-attachment\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"gill-spacing\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"gill-size\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"gill-color\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"stalk-shape\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"stalk-root\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"stalk-surface-above-ring\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"stalk-surface-below-ring\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"stalk-color-above-ring\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"stalk-color-below-ring\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"veil-color\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"ring-number\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"ring-type\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"spore-print-color\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"population\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"habitat\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "    }, crosses=[\n",
    "        # Cap-Color and Cap Shape\n",
    "        FeatureSpace.cross(\n",
    "            feature_names= ('cap-color', 'cap-shape'),\n",
    "            crossing_dim= 10*6),\n",
    "        # Odor and Gill-Color\n",
    "        FeatureSpace.cross(\n",
    "            feature_names= ('gill-color', 'odor'),\n",
    "            crossing_dim= 12*9),\n",
    "        # Bruises and Stalk-Surface-above-ring\n",
    "        FeatureSpace.cross(\n",
    "            feature_names= ('bruises', 'stalk-surface-above-ring'),\n",
    "            crossing_dim= 2*4),\n",
    "        # Bruises and Stalk-Surface-below-ring\n",
    "        FeatureSpace.cross(\n",
    "            feature_names= ('bruises', 'stalk-surface-below-ring'),\n",
    "            crossing_dim= 2*4),\n",
    "        # Ring-Type and Stalk-Color-below ring\n",
    "        FeatureSpace.cross(\n",
    "            feature_names= ('ring-type', 'stalk-color-below-ring'),\n",
    "            crossing_dim= 8*8),\n",
    "        # Ring-Type and Stalk-Color-above ring\n",
    "        FeatureSpace.cross(\n",
    "            feature_names= ('ring-type', 'stalk-color-above-ring'),\n",
    "            crossing_dim= 8*8),\n",
    "        # Spore-Print Color and Habitat\n",
    "        FeatureSpace.cross(\n",
    "            feature_names= ('spore-print-color', 'habitat'),\n",
    "            crossing_dim= 9*7)\n",
    "    ],\n",
    "    output_mode=\"concat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we establish the feature space utilized by our network. Initially, we inform Keras that all integer values within the dataframe denote categorical values. This specification will prove advantageous when we proceed to one-hot encode this data in the subsequent section.\n",
    "\n",
    "After conducting preliminary research into various qualities and characteristics commonly associated with poisonous mushrooms, we found that we could use some of our features from our dataset to combine them into cross-product features possibly improving the predictive performance of the model in distinguishing between edible and poisonous mushrooms.\n",
    "\n",
    "We found we combine the following features into the feature space:\n",
    "\n",
    "- **Cap-Color X Cap-Shape**: Certain combinations of cap color and shape might be more indicative of edible or poisonous mushrooms. For example, convex-shaped mushrooms with a brown cap color might be more likely to be edible, while flat-shaped mushrooms with a red cap color might be more likely to be poisonous.\n",
    "\n",
    "- **Odor X Gill-Color**: The combination of odor and gill color can provide valuable information. For instance, mushrooms with a foul odor and black gills might be more likely to be poisonous, while mushrooms with an almond-like odor and white gills might be more likely to be edible.\n",
    "\n",
    "- **Bruises X Stalk-Surface**: Combining bruises and stalk surface texture could capture interactions related to the mushroom's response to damage. For example, mushrooms that bruise easily and have a silky stalk surface might be more likely to be poisonous.\n",
    "\n",
    "- **Ring-Type X Stalk-Color**: Certain combinations of ring type and stalk color might be indicative of edible or poisonous mushrooms. For instance, mushrooms with an evanescent ring type and a brown stalk color might be more likely to be edible.\n",
    "\n",
    "- **Spore-Print-Color X Habitat**: Combining spore print color and habitat could capture interactions related to the mushroom's reproductive characteristics and preferred environment. For example, mushrooms with a brown spore print color found in wooded habitats might be more likely to be edible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [1 points] Choose and explain what metric(s) you will use to evaluate your algorithm’s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin modeling, we must ensure what evaluation metrics are appropriate for evaluating our networks performance, as it pertains to our buisness case. For evaluating our network's performance on classifying mushrooms as edible or poisonous, using the Area Under the Receiver Operating Characteristic Curve (AUC-ROC) is a prudent choice, particularly due to the critical nature of the classification task.\n",
    "\n",
    "The primary concern in classifying mushrooms is the potential severe health risks associated with incorrectly identifying a poisonous mushroom as edible. In this context, the consequences of false negatives (wrongly predicting that a poisonous mushroom is edible) are far more severe than false positives (erroneously identifying an edible mushroom as poisonous). The AUC-ROC metric provides a comprehensive measure of the model’s ability to correctly classify both classes across all possible thresholds, emphasizing the capability to distinguish between the two with high sensitivity (true positive rate) and specificity (true negative rate).\n",
    "\n",
    "Since our primary goal is to avoid false negatives, the ROC curve (which plots the true positive rate against the false positive rate) helps in visualizing and choosing a model with the least number of false negatives at an acceptable false positive rate level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [1 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Argue why your cross validation method is a realistic mirroring of how an algorithm would be used in practice. Use the method to split your data that you argue for. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "shuffle_split = ShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in shuffle_split.split(data):\n",
    "  df_train= data.iloc[train_index]\n",
    "  df_test= data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To divide our dataset for training and testing purposes, we will employ the shuffle split method from the model_selection package in Scikit-Learn. This method is particularly suitable for our dataset given its relatively balanced composition, with 52% of the observations being edible and 48% poisonous. The even distribution facilitates the use of the shuffle split method, which is not only faster but also less computationally demanding. We have opted for an 80-20 split between the training and testing sets, respectively. This ratio helps minimize the risk of overfitting while ensuring that the testing set remains adequately large to verify the model's performance effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['edible'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creating Tensors for train and test datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m categorical_headers\u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medible\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      3\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_dataset_from_dataframe\u001b[39m(df_input):\n",
      "File \u001b[1;32mc:\\Users\\ncast\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ncast\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\ncast\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ncast\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['edible'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Creating Tensors for train and test datasets\n",
    "categorical_headers= data.drop(columns=['edible']).columns\n",
    "batch_size= 64\n",
    "\n",
    "def create_dataset_from_dataframe(df_input):\n",
    "\n",
    "    df = df_input.copy()\n",
    "    labels = data['edible']\n",
    "\n",
    "    df = {key: value.values[:,np.newaxis] for key, value in df_input[categorical_headers].items()}\n",
    "\n",
    "    # create the Dataset here\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "\n",
    "    # now enable batching and prefetching\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "\n",
    "    return ds\n",
    "\n",
    "ds_train= create_dataset_from_dataframe(df_train)\n",
    "ds_test= create_dataset_from_dataframe(df_test)\n",
    "\n",
    "# Performing One Hot Encoding\n",
    "ds_train_no_label= ds_train.map(lambda x, _: x)\n",
    "feature_space.adapt(ds_train_no_label)\n",
    "\n",
    "train_ds_with_no_labels = ds_train.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we start by converting our Pandas DataFrame into a TensorFlow Tensor. This conversion is facilitated by a function taken from example 10a on our class's GitHub repository. Once we have transformed the train and test datasets into tensors, we can straightforwardly apply one-hot encoding using the Keras Feature Space object that was established in the preceding section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (5 points total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [2 points] Create at least three combined wide and deep networks to classify your data using Keras (this total of \"three\" includes the model you will train in the next step of the rubric). Visualize the performance of the network on the training data and validation data in the same plot versus the training iterations.\n",
    "\n",
    "> *Note: you can use the \"history\" return parameter that is part of Keras \"fit\" function to easily access this data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [2 points] Investigate generalization performance by altering the number of layers in the deep branch of the network. Try at least two models (this \"two\" includes the wide and deep model trained from the previous step). Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab to answer: What model with what number of layers performs superiorly? Use proper statistical methods to compare the performance of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [1 points] Compare the performance of your best wide and deep network to a standard multi-layer perceptron (MLP). Alternatively, you can compare to a network without the wide branch (i.e., just the deep network). For classification tasks, compare using the receiver operating characteristic and area under the curve. For regression tasks, use Bland-Altman plots and residual variance calculations.  Use proper statistical methods to compare the performance of different models.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work (1 points total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
