{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab 3: The Multi-Layer Perception**\n",
    "### Authors: Will Lahners, Edward Powers, and Nino Castellano\n",
    "________________________________________________________________\n",
    "\n",
    "## **Describing the Data**\n",
    "\n",
    "This dataset from Kaggle, contains US Census data taken from the DP03 and DP05 tables of the 2015 American Community Survey 5-year estimates. We will be utilizing the *acs2015_census_tract_data.csv* file which is data for each census tract in the US, including DC and Puerto Rico. A tract ID, also known as a GEOID (Geographic Identifier), is a numeric code assigned to specific geographic areas by the Census Bureau and other state and federal agencies. These codes uniquely identify various administrative, legal, and statistical geographic entities for which the Census Bureau collects and tabulates data. Our classification task we will be:\n",
    "\n",
    "- Predicting, for each tract ID, what the child poverty rate will be. \n",
    "\n",
    "We are converting this from regression to four levels of classification by quantizing the variable of interest. \n",
    "\n",
    "## **Load, Split, and Balance (1.5 points total)**\n",
    "\n",
    "***[.5 points]** **(1)** Load the data into memory and save it to a pandas data frame. Do not normalize or one-hot encode any of the features until asked to do so later in the rubric. **(2)** Remove any observations that having missing data. **(3)** Encode any string data as integers for now. **(4)** You have the option of keeping the \"county\" variable or removing it. Be sure to discuss why you decided to keep/remove this variable.*\n",
    "\n",
    "We've decided to go ahead with the option of removing the \"County\" variable due to the fact that our primary focus is on the TractId's. Including the county would be extra unnecessary data given that their could be multiple TractId's in the same county. However, the same could be said about the \"States\" as well but there aren't as many states as there is counties so that leads to more computational power when eventually one-hot encoding these features which is another reason why we decided to remove it. There are only 52 states in total compared to the hundreds of counties. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 72718 entries, 0 to 74000\n",
      "Data columns (total 36 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           72718 non-null  int64  \n",
      " 1   State             72718 non-null  int64  \n",
      " 2   TotalPop          72718 non-null  int64  \n",
      " 3   Men               72718 non-null  int64  \n",
      " 4   Women             72718 non-null  int64  \n",
      " 5   Hispanic          72718 non-null  float64\n",
      " 6   White             72718 non-null  float64\n",
      " 7   Black             72718 non-null  float64\n",
      " 8   Native            72718 non-null  float64\n",
      " 9   Asian             72718 non-null  float64\n",
      " 10  Pacific           72718 non-null  float64\n",
      " 11  VotingAgeCitizen  72718 non-null  int64  \n",
      " 12  Income            72718 non-null  float64\n",
      " 13  IncomeErr         72718 non-null  float64\n",
      " 14  IncomePerCap      72718 non-null  float64\n",
      " 15  IncomePerCapErr   72718 non-null  float64\n",
      " 16  Poverty           72718 non-null  float64\n",
      " 17  ChildPoverty      72718 non-null  float64\n",
      " 18  Professional      72718 non-null  float64\n",
      " 19  Service           72718 non-null  float64\n",
      " 20  Office            72718 non-null  float64\n",
      " 21  Construction      72718 non-null  float64\n",
      " 22  Production        72718 non-null  float64\n",
      " 23  Drive             72718 non-null  float64\n",
      " 24  Carpool           72718 non-null  float64\n",
      " 25  Transit           72718 non-null  float64\n",
      " 26  Walk              72718 non-null  float64\n",
      " 27  OtherTransp       72718 non-null  float64\n",
      " 28  WorkAtHome        72718 non-null  float64\n",
      " 29  MeanCommute       72718 non-null  float64\n",
      " 30  Employed          72718 non-null  int64  \n",
      " 31  PrivateWork       72718 non-null  float64\n",
      " 32  PublicWork        72718 non-null  float64\n",
      " 33  SelfEmployed      72718 non-null  float64\n",
      " 34  FamilyWork        72718 non-null  float64\n",
      " 35  Unemployment      72718 non-null  float64\n",
      "dtypes: float64(29), int64(7)\n",
      "memory usage: 20.5 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TractId</th>\n",
       "      <th>State</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Pacific</th>\n",
       "      <th>VotingAgeCitizen</th>\n",
       "      <th>Income</th>\n",
       "      <th>IncomeErr</th>\n",
       "      <th>IncomePerCap</th>\n",
       "      <th>IncomePerCapErr</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>ChildPoverty</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Service</th>\n",
       "      <th>Office</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Production</th>\n",
       "      <th>Drive</th>\n",
       "      <th>Carpool</th>\n",
       "      <th>Transit</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>1</td>\n",
       "      <td>1845</td>\n",
       "      <td>899</td>\n",
       "      <td>946</td>\n",
       "      <td>2.4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1407</td>\n",
       "      <td>67826.0</td>\n",
       "      <td>14560.0</td>\n",
       "      <td>33018.0</td>\n",
       "      <td>6294.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>20.8</td>\n",
       "      <td>38.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>22.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>94.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>881</td>\n",
       "      <td>74.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>1</td>\n",
       "      <td>2172</td>\n",
       "      <td>1167</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1652</td>\n",
       "      <td>41287.0</td>\n",
       "      <td>3819.0</td>\n",
       "      <td>18996.0</td>\n",
       "      <td>2453.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>35.8</td>\n",
       "      <td>30.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>15.4</td>\n",
       "      <td>90.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>852</td>\n",
       "      <td>75.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>1</td>\n",
       "      <td>3385</td>\n",
       "      <td>1533</td>\n",
       "      <td>1852</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2480</td>\n",
       "      <td>46806.0</td>\n",
       "      <td>9496.0</td>\n",
       "      <td>21236.0</td>\n",
       "      <td>2562.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>27.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>33.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>88.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1482</td>\n",
       "      <td>73.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>1</td>\n",
       "      <td>4267</td>\n",
       "      <td>2001</td>\n",
       "      <td>2266</td>\n",
       "      <td>9.6</td>\n",
       "      <td>80.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3257</td>\n",
       "      <td>55895.0</td>\n",
       "      <td>4369.0</td>\n",
       "      <td>28068.0</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>25.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>19.5</td>\n",
       "      <td>82.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1849</td>\n",
       "      <td>75.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>1</td>\n",
       "      <td>9965</td>\n",
       "      <td>5054</td>\n",
       "      <td>4911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7229</td>\n",
       "      <td>68143.0</td>\n",
       "      <td>14424.0</td>\n",
       "      <td>36905.0</td>\n",
       "      <td>10706.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>48.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>86.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4787</td>\n",
       "      <td>71.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TractId  State  TotalPop   Men  Women  Hispanic  White  Black  Native  \\\n",
       "0  1001020100      1      1845   899    946       2.4   86.3    5.2     0.0   \n",
       "1  1001020200      1      2172  1167   1005       1.1   41.6   54.5     0.0   \n",
       "2  1001020300      1      3385  1533   1852       8.0   61.4   26.5     0.6   \n",
       "3  1001020400      1      4267  2001   2266       9.6   80.3    7.1     0.5   \n",
       "4  1001020500      1      9965  5054   4911       0.9   77.5   16.4     0.0   \n",
       "\n",
       "   Asian  Pacific  VotingAgeCitizen   Income  IncomeErr  IncomePerCap  \\\n",
       "0    1.2      0.0              1407  67826.0    14560.0       33018.0   \n",
       "1    1.0      0.0              1652  41287.0     3819.0       18996.0   \n",
       "2    0.7      0.4              2480  46806.0     9496.0       21236.0   \n",
       "3    0.2      0.0              3257  55895.0     4369.0       28068.0   \n",
       "4    3.1      0.0              7229  68143.0    14424.0       36905.0   \n",
       "\n",
       "   IncomePerCapErr  Poverty  ChildPoverty  Professional  Service  Office  \\\n",
       "0           6294.0     10.7          20.8          38.5     15.6    22.8   \n",
       "1           2453.0     22.4          35.8          30.5     24.9    22.9   \n",
       "2           2562.0     14.7          21.1          27.9     19.4    33.3   \n",
       "3           3190.0      2.3           1.7          29.0     16.6    25.8   \n",
       "4          10706.0     12.2          17.9          48.8     13.8    20.5   \n",
       "\n",
       "   Construction  Production  Drive  Carpool  Transit  Walk  OtherTransp  \\\n",
       "0          10.8        12.4   94.2      3.3      0.0   0.5          0.0   \n",
       "1           6.3        15.4   90.5      9.1      0.0   0.0          0.5   \n",
       "2           9.9         9.6   88.3      8.4      0.0   1.0          0.8   \n",
       "3           9.1        19.5   82.3     11.2      0.0   1.5          2.9   \n",
       "4           3.5        13.4   86.9     11.2      0.0   0.8          0.3   \n",
       "\n",
       "   WorkAtHome  MeanCommute  Employed  PrivateWork  PublicWork  SelfEmployed  \\\n",
       "0         2.1         24.5       881         74.2        21.2           4.5   \n",
       "1         0.0         22.2       852         75.9        15.0           9.0   \n",
       "2         1.5         23.1      1482         73.3        21.1           4.8   \n",
       "3         2.1         25.9      1849         75.8        19.7           4.5   \n",
       "4         0.7         21.0      4787         71.4        24.1           4.5   \n",
       "\n",
       "   FamilyWork  Unemployment  \n",
       "0         0.0           4.6  \n",
       "1         0.0           3.4  \n",
       "2         0.7           4.7  \n",
       "3         0.0           6.1  \n",
       "4         0.0           2.3  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# (1) Load the data into a pandas DataFrame\n",
    "data = pd.read_csv('./acs2017_census_tract_data.csv')\n",
    "\n",
    "# (2) Remove observations that have missing data\n",
    "data = data.dropna()\n",
    "\n",
    "# (3) Encode any string data as integers for now (Credits to ChatGPT)\n",
    "states = data['State'].unique()\n",
    "state_to_int_mapping = {state: idx + 1 for idx, state in enumerate(states)} \n",
    "data['State'] = data['State'].map(state_to_int_mapping)\n",
    "\n",
    "# (4) Removing \"County\" variable\n",
    "data = data.drop(columns=['County']) \n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The next two requirements will need to be completed together as they might depend on one another:*\n",
    "\n",
    "***[.5 points]** Balance the dataset so that about the same number of instances are within each class. Choose a method for balancing the dataset and explain your reasoning for selecting this method. One option is to choose quantization thresholds for the \"ChildPoverty\" variable that equally divide the data into four classes. Should balancing of the dataset be done for both the training and testing set? Explain.*\n",
    "\n",
    "We decided to go along the balancing method suggested in the instructions, quantizing the \"ChildPoverty\" variable into four different classes. This is because using quantization thresholds for balancing the dataset simplifies the classification task by categorizing the poverty rate into discrete levels, such as low, medium, high, and very high. This approach ensures a balanced representation of each category and facilitates clear interpretation of the results, aiding policymakers in understanding poverty severity across different areas. By mitigating imbalanced data challenges and providing meaningful bins, quantization supports the objective of predicting poverty levels for each Tract ID and informs targeted interventions and policies to address disparities effectively.\n",
    "\n",
    "Also regarding the question of balancing both the training and testing sets, we believe that just balancing the training set would be more effective. While it's essential to balance the training set to ensure the model learns from a diverse set of instances, it's equally important to evaluate the model on an unbiased testing set that reflects the true distribution of classes in real-world data. Therefore, balancing should typically be applied to the training set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TractId</th>\n",
       "      <th>State</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Pacific</th>\n",
       "      <th>VotingAgeCitizen</th>\n",
       "      <th>Income</th>\n",
       "      <th>IncomeErr</th>\n",
       "      <th>IncomePerCap</th>\n",
       "      <th>IncomePerCapErr</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Service</th>\n",
       "      <th>Office</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Production</th>\n",
       "      <th>Drive</th>\n",
       "      <th>Carpool</th>\n",
       "      <th>Transit</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>ChildPovertyClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>1</td>\n",
       "      <td>1845</td>\n",
       "      <td>899</td>\n",
       "      <td>946</td>\n",
       "      <td>2.4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1407</td>\n",
       "      <td>67826.0</td>\n",
       "      <td>14560.0</td>\n",
       "      <td>33018.0</td>\n",
       "      <td>6294.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>22.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>94.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>881</td>\n",
       "      <td>74.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>1</td>\n",
       "      <td>2172</td>\n",
       "      <td>1167</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1652</td>\n",
       "      <td>41287.0</td>\n",
       "      <td>3819.0</td>\n",
       "      <td>18996.0</td>\n",
       "      <td>2453.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>30.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>15.4</td>\n",
       "      <td>90.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>852</td>\n",
       "      <td>75.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>1</td>\n",
       "      <td>3385</td>\n",
       "      <td>1533</td>\n",
       "      <td>1852</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2480</td>\n",
       "      <td>46806.0</td>\n",
       "      <td>9496.0</td>\n",
       "      <td>21236.0</td>\n",
       "      <td>2562.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>27.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>33.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>88.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1482</td>\n",
       "      <td>73.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>1</td>\n",
       "      <td>4267</td>\n",
       "      <td>2001</td>\n",
       "      <td>2266</td>\n",
       "      <td>9.6</td>\n",
       "      <td>80.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3257</td>\n",
       "      <td>55895.0</td>\n",
       "      <td>4369.0</td>\n",
       "      <td>28068.0</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>25.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>19.5</td>\n",
       "      <td>82.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1849</td>\n",
       "      <td>75.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>1</td>\n",
       "      <td>9965</td>\n",
       "      <td>5054</td>\n",
       "      <td>4911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7229</td>\n",
       "      <td>68143.0</td>\n",
       "      <td>14424.0</td>\n",
       "      <td>36905.0</td>\n",
       "      <td>10706.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>48.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>86.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4787</td>\n",
       "      <td>71.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TractId  State  TotalPop   Men  Women  Hispanic  White  Black  Native  \\\n",
       "0  1001020100      1      1845   899    946       2.4   86.3    5.2     0.0   \n",
       "1  1001020200      1      2172  1167   1005       1.1   41.6   54.5     0.0   \n",
       "2  1001020300      1      3385  1533   1852       8.0   61.4   26.5     0.6   \n",
       "3  1001020400      1      4267  2001   2266       9.6   80.3    7.1     0.5   \n",
       "4  1001020500      1      9965  5054   4911       0.9   77.5   16.4     0.0   \n",
       "\n",
       "   Asian  Pacific  VotingAgeCitizen   Income  IncomeErr  IncomePerCap  \\\n",
       "0    1.2      0.0              1407  67826.0    14560.0       33018.0   \n",
       "1    1.0      0.0              1652  41287.0     3819.0       18996.0   \n",
       "2    0.7      0.4              2480  46806.0     9496.0       21236.0   \n",
       "3    0.2      0.0              3257  55895.0     4369.0       28068.0   \n",
       "4    3.1      0.0              7229  68143.0    14424.0       36905.0   \n",
       "\n",
       "   IncomePerCapErr  Poverty  Professional  Service  Office  Construction  \\\n",
       "0           6294.0     10.7          38.5     15.6    22.8          10.8   \n",
       "1           2453.0     22.4          30.5     24.9    22.9           6.3   \n",
       "2           2562.0     14.7          27.9     19.4    33.3           9.9   \n",
       "3           3190.0      2.3          29.0     16.6    25.8           9.1   \n",
       "4          10706.0     12.2          48.8     13.8    20.5           3.5   \n",
       "\n",
       "   Production  Drive  Carpool  Transit  Walk  OtherTransp  WorkAtHome  \\\n",
       "0        12.4   94.2      3.3      0.0   0.5          0.0         2.1   \n",
       "1        15.4   90.5      9.1      0.0   0.0          0.5         0.0   \n",
       "2         9.6   88.3      8.4      0.0   1.0          0.8         1.5   \n",
       "3        19.5   82.3     11.2      0.0   1.5          2.9         2.1   \n",
       "4        13.4   86.9     11.2      0.0   0.8          0.3         0.7   \n",
       "\n",
       "   MeanCommute  Employed  PrivateWork  PublicWork  SelfEmployed  FamilyWork  \\\n",
       "0         24.5       881         74.2        21.2           4.5         0.0   \n",
       "1         22.2       852         75.9        15.0           9.0         0.0   \n",
       "2         23.1      1482         73.3        21.1           4.8         0.7   \n",
       "3         25.9      1849         75.8        19.7           4.5         0.0   \n",
       "4         21.0      4787         71.4        24.1           4.5         0.0   \n",
       "\n",
       "   Unemployment ChildPovertyClass  \n",
       "0           4.6                 1  \n",
       "1           3.4                 2  \n",
       "2           4.7                 1  \n",
       "3           6.1                 3  \n",
       "4           2.3                 1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Quantization thresholds for Balancing\n",
    "data['ChildPovertyClass'] = pd.qcut(data['ChildPoverty'], q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Dropping the orginal Child Poverty Variable since we now have the 4 classes\n",
    "data.drop(['ChildPoverty'], axis = 1, inplace = True)\n",
    "\n",
    "# Tranform the Labels into discret values 0, 1, 2, 3\n",
    "classes = data['ChildPovertyClass'].unique()\n",
    "class_to_int_mapping = {i: idx + 1 for idx, i in enumerate(classes)} \n",
    "data['ChildPovertyClass'] = data['ChildPovertyClass'].map(class_to_int_mapping)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***[.5 points]** Assume you are equally interested in the classification performance for each class in the dataset. Split the dataset into 80% for training and 20% for testing. There is no need to split the data multiple times for this lab.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Handaling Target Variable\n",
    "X = data.drop(columns=['ChildPovertyClass']).to_numpy()\n",
    "y = data['ChildPovertyClass'].to_numpy()\n",
    "\n",
    "# Test and Train using 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split the data into training and testing sets, using the 80/20 split. Given that we are equally interested in the classification performance for each class, we stratified the sets to ensure each class is equally represented within both the training and testing data, reducing the biased toward one class over the others.\n",
    "\n",
    "*Note: You will need to one hot encode the target, but do not one hot encode the categorical data until instructed to do so in the lab.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pre-processing and Initial Modeling (2.5 points total)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
